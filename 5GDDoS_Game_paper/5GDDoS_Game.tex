\documentclass[conference]{IEEEtran}
\usepackage{bm}
\usepackage{cite}
\usepackage{ragged2e}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{etoolbox}
\usepackage{mathrsfs}
\usepackage{subfig}
\usepackage{array}
\usepackage{cases}
\usepackage{dsfont}
\usepackage{optidef}
\usepackage{cleveref}

\allowdisplaybreaks
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\setlength{\columnsep}{0.21in}
\makeatletter
\newcommand\fs@betterruled{%
  \def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@ruled
  \def\@fs@pre{\vspace*{0.03in}\hrule height.8pt depth0pt \kern2pt}%
  \def\@fs@post{\kern2pt\hrule\relax}%
  \def\@fs@mid{\kern2pt\hrule\kern2pt}%
  \let\@fs@iftopcapt\iftrue}
\floatstyle{betterruled}
\restylefloat{algorithm}
\makeatother
\renewcommand{\arraystretch}{1.2}
\begin{document}
\title{Game-Theoretic Intrusion Prevention System Deployment for Mobile Edge Computing}
\author{\IEEEauthorblockN{Zhan-Lun Chang\IEEEauthorrefmark{1}, Chun-Yen Lee\IEEEauthorrefmark{2}, Chia-Hung Lin\IEEEauthorrefmark{2},
Chih-Yu Wang\IEEEauthorrefmark{1}, Hung-Yu Wei\IEEEauthorrefmark{2}}
\IEEEauthorblockA{
\IEEEauthorrefmark{1}Research Center for Information Technology Innovation, Academia Sinica\\
\IEEEauthorrefmark{2}Department of Electrical Engineering, National Taiwan University
%zhc915@citi.sinica.edu.tw, b06203017@ntu.edu.tw, b06504016@ntu.edu.tw, cywang@citi.sinica.edu.tw, hywei@ntu.edu.tw,
}}
\maketitle

\begin{abstract}
The network attack such as Distributed Denial-of-Service (DDoS) attack could be critical to latency-critical systems such as Mobile Edge Computing (MEC) as such attacks significantly increase the response delay of the victim service. Intrusion prevention system (IPS) is a promising solution to defend against such attacks, but there will be a trade-off between IPS deployment and application resource reservation as the deployment of IPS will reduce the number of computation resources for MEC applications. In this paper, we proposed a game-theoretic framework to study the joint computation resource allocation and IPS deployment in the MEC architecture. We study the pricing strategy of the MEC platform operator and purchase strategy of the application service provider, given the expected attack strength and end user demands. The best responses of both MPO and ASPs are derived theoretically to identify the Stackelberg equilibrium. The simulation results confirm that the proposed solutions significantly increase the social welfare of the system.
\end{abstract}

\section{Introduction}
Mobile edge computing (MEC) is a promising technique to provide low-latency computing services. MEC platform providers (MPOs) deploy MEC servers at the network edge to provide computation resources for latency-critical tasks. Application service providers (ASPs) purchase those resources to deploy their applications for the end users. This architecture serves as the foundation of 5G/B5G killer applications such as Vehicle Automation, AR/VR, Smart City, etc.

Nevertheless, the network attack has been considered a serious threat to most network services. One of the most common attacks is the Distributed Denial-of-Service (DDoS) attack, which is performed by a significant number of infected devices to send fake requests to the victim service. The service requests of normal end users will be denied afterward due to that the victim service is out of resources. We observe that DDoS would be critical in the MEC architecture, as the available resource at the MEC servers are usually limited and cannot be expanded, while the deployed applications are mostly latency-critical and cannot tolerate service denial. A defensive measurement is necessary to guarantee the MEC service quality under the foreseen DDoS attacks.

Intrusion prevention system (IPS) is an effective measurement to identify and respond to the malicious behaviors performed by the attackers. In DDoS attack, for instance, an effective IPS instance can identify those malicious requests and isolate them from the service requests from the normal end users. Nevertheless, due to the deployment limitation of network edge environment, the candidate IPS for MEC is likely to be software-based, which means there will be a trade-off between IPS deployment and application resource reservation: the deployment of IPS will reduce the amount of computation resource for applications as some are occupied by the IPS instances, and thus the service latency may increase accordingly. On the other hand, lacking sufficient IPS will make the application vulnerable to DDoS attacks. Such a trade-off should be considered by the ASP when deploying its application at the MEC system. 

In this paper, we proposed a game-theoretic framework to study the joint computation resource allocation and IPS deployment in the MEC architecture, from the economic perspective. Specifically, the MPO provides the MEC computation resource in the form of virtual machines with a price. The ASPs buy the VM from the MPO to deploy their applications, and the IPS can be optionally deployed if the DDoS attack is expected. In the proposed framework, we form the problem as a Stackelberg game to study the pricing strategy of the MPO and the optimal amount of VMs for application and IPS deployment of the ASPs. The best responses of both MPO and ASPs are derived theoretically to identify the Stackelberg equilibrium. The simulation results confirm that the proposed solutions significantly increase the social welfare of the system, that is, the total benefit of the whole MEC system.


\begin{figure}[t]
\centering
\includegraphics[width= 0.8\columnwidth]{5GDDoS_Game_system_architecture.pdf}
\caption{System Architecture}
\vspace{-0.6em}
\label{fig:system}
\end{figure}


The main contributions of this work are as follows:
\begin{enumerate}
    \item To the best of our knowledge, we are the first group to study the DDoS attack and defense measurements in the MEC environment in a game-theoretic approach. This approach will help both MPO and ASPs to optimize their configurations in terms of their economic benefits.
    \item We propose a flexible IPS deployment strategy to defend DDoS attack at MEC system by allowing ASPs to determine the resource allocation for IPS and main service according to the expected attack strength. 
    \item The optimal strategies of both MPO and ASPs are analyzed through the proposed Stackelberg game model, which can be used to identify the equilibrium in polynomial time. The simulation results verify the effectiveness of the proposed solution in maintaining social welfare. 
\end{enumerate}

\section{Related Work}
Intrusion detection has been proposed with different approaches, including entropy-based method \cite{Wang}, reinforcement learning \cite{Zhang}, and Deep Convolution Neural Network Q-learning model \cite{Liu}. Several studies have been conducted to defend against DDoS attacks in the MEC environment.  Alharbi \emph{et al.} introduced NFV and edge computing architecture to design a two-stage DDoS mitigation network \cite{Alharbi}. Mert \emph{et al.}  provided a similar paradigm that security function on edge computing defend the DDoS attack\cite{Mert}. A multi-level DDoS mitigation framework \cite{Yan} was proposed by Yan \emph{et al.}  to mitigate the DDoS attack to IoT. Shen \emph{et al.} \cite{Shen} implemented a Two-Phase DDoS detection system and showed that it can detect attacks with smaller overhead. Furthermore. Yang \emph{et al.} devised a collaborative task offloading scheme to balance the task load between overloaded and underloaded cloudlets \cite{Yang}. Li \emph{et al.} explored the cooperative defense strategy and provided an online cooperative defense framework\cite{Li}. Introduced by Mtibaa \emph{et al.} , detecting and isolating malicious nodes for D2D communication was proposed \cite{Mtibaa}. 

Distinguished from previous works, we focus on the resource allocation problems when defending DDoS attacks from the economic perspective of both MPO and ASPs. We use the Stackelberg game to formulate the relationships between MPO and ASPs and solve the optimization problems to maximize the utility of both sides under the DDoS attacks.

\section{System Model}

We consider a system with a MEC platform operator (MPO), a set of application service providers (ASPs) $\mathcal{I}=\{1, \cdots, I\}$, and end-users (EUs) (Fig~\ref{fig:system}). The MPO manages the computation resources in terms of virtual machines (VMs). The ASPs request for the MPO's VMs to deploy their applications. The goal of the MPO is to maximize its profit by finding the optimal unit selling price $\Psi_{m}^v$ per VM.  The ASPs determine the number of VMs to buy (denoted by $z_i^v$) from MPO to maximize their profit. Then, we denote the set of EUs associated with ASP $i \in \mathcal{I}$ as $\mathrm{U}_i$ and further categorize it into two kinds: normal users (NUs) $\mathrm{U}_i^n$ and malicious users (MUs) $\mathrm{U}_i^m$. NUs seek the service from the ASPs with latency requirements, while the MUs aim to interrupt the service by sending fake tasks. Each EU $j \in \mathrm{U}_i$ has the Poisson task arrival rate $\lambda_{ij}$, latency requirement $d_{ij}$, and task size $s_{ij}$. We assume the EUs cannot handle these tasks locally because they rely on the computation resources and backbone model/database offered by the ASPs. 


The ASPs utilize these purchased VMs to either run the application service for NUs or mitigate the DDoS security attacks from MUs. If ASPs devote most of their VMs to running the application service, they are prone to DDoS security attacks from MUs. The security threat would damage the quality of experience (QoE) of NUs and thus the revenue of ASPs. On the other hand, if the ASPs devote most of their VMs to mitigating the DDoS attack, the latency requirements of NUs may still not be satisfied if the available resource is not enough. Therefore, it is crucial to find an optimal resource allocation between running the application service and mitigating the DDoS attacks. 

Specifically, the ASPs can intercept malicious requests by employing a software-based intrusion prevention system (IPS) \cite{Suricata}. The IPS of all ASPs monitors and filters all task requests, and all VMs devoted to running the application service process the filtered task requests. We assume the IPS can perfectly identify the normal task requests, but it may classify some malicious task requests as normal. The number of malicious requests the IPS filter can filter depends on the number of VMs the ASPs dedicate to the IPS. We use $H(\cdot)$ to represent the relationship between the quantity of intercepted malicious requests and the number of devoted VMs. $H(\cdot)$ is assumed to be non-decreasing and concave. Also, $H(0)=0$. In this paper, we consider a linear function form of $H(x) = \eta{x}$, where $\eta$ denotes the IPS efficiency. %so that the closed form solutions can be derived in the following optimization problems. 
%The cost of using IPS only comes from the devoted VMs and does not include any payment because it is open-source.

We consider orthogonal frequency-division multiple access (OFDMA) system and thus the bandwidth of the edge servers whose computation resources are allocated to ASP $i$ denoted by $B_i$ can be divided into $|\mathrm{U}_i|$ sub-bands of size $W_{i} = B_i/|\mathrm{U}_i|$. Each EU $j\in \mathrm{U}_i$ transmits the data at a dedicated sub-band to avoid interference. The maximum achievable uplink data transmission rate $R_{ij}$ between ASP $i$ and EU $j \in \mathrm{U}_i$ is
\begin{equation} \label{eqn:shannon}
R_{ij}=W_i \cdot log_2\Big(1+\frac{p_{ij}g_{ij}}{N_{0}}\Big),
\end{equation}
where $p_{ij}$ is the maximum transmission power of EU $j$ in $\mathrm{U}_i$, and $g_{ij}$ denotes the uplink channel gain between ASP $i$ and EU $j$. $N_0$ is the background noise power. The mean transmission time of workload consisting of tasks with size $s_{ij}$ from EU $j \in \mathrm{U}_i$ to ASP $i$ is
\begin{equation}
T_{ij}^t=\frac{\lambda_{ij} \cdot s_{ij}}{R_{ij}}.
\end{equation}

The task arrival process at ASP $i$ also follows the Poisson process according to the Poisson process's stationary property. Specifically, the mean arriving rate of the Poisson process at ASP $i$ can be expressed as $\lambda_i = \sum_{j \in \mathrm{U}_i} \lambda_{ij}$ based on the superposition property of the Poisson process. Since the ASPs buy VMs from the MPO whose overall computation resources are still limited compared to the cloud platform, we model the meaning processing delay of all VMs purchased by ASPs using the $M/M/1$ queue. Each VM of MPO is homogeneous and can process $f_m^v$ CPU cycles per second. As the average required CPU cyles for a task of ASP $i$ may be different, the mean service rate of the queue at ASP $i$ denoted by $\mu_i^v$ (in task per second) is different for every ASP $i$. We denote the required CPU cycles of user $j \in \mathsf{U}_i$ as $\chi_{ij}$. The relationship between $f_m^v$ and $\mu_i^v$ is
\begin{equation}
\mu_i^v = f_m^v/(\frac{\sum_{j \in \mathsf{U}_i} \chi_{ij}}{|\mathrm{U}_i|})
\end{equation}
If the ASP $i$ devotes $z_i^h$ out of $z_i^v$ VMs to IPS, the intercepted quantity of malicious requests is $H(z_i^h)$. When ASP $i$ buys $z_i^v$ VMs from the MPO and devotes $z_i^h$ to IPS, those VMs' mean processing delay is
\begin{equation} \label{eqn:asp_mm1_delay}
T_i^p(z_i^v, z_i^h) = \frac{1}{(z_i^v - z_i^h)\mu_i^v - \big(\lambda_i - H(z_i^h)\big)}
\end{equation}

The payment from NU $j \in \mathrm{U}_i^n$ to the ASP $i$ depends on whether the latency requirements $d_{ij} \, \forall j \in \mathrm{U}_i^n$ are satisfied. NU $j \in \mathrm{U}_i^n$ pays a price $\Psi_{ij}$ to ASP $i$ only if latency requirements $d_{ij}$ are met. The heterogeneity of the payment reflects the different characteristics of NUs. The MUs $j \in \mathrm{U}_i^m$, on the other hand, will not pay any money to the ASP $i$ in any case. We represent the payment of EU $j \in \mathrm{U}_i$:
\begin{subnumcases}{\mathcal{K}_{ij}(z_i^v, z_i^h)=\label{eqn:devicepayment}}
  \Psi_{ij} & \hspace*{-1.7mm}if $T_{ij}^t + T_i^p(z_i^v, z_i^h) \leq d_{ij}$, $j \in \mathrm{U}_i^n$\\
  0 & \hspace*{-1.7mm}if $T_{ij}^t + T_i^p(z_i^v, z_i^h) > d_{ij}$, $j \in \mathrm{U}_i^n$ \\
  0 & \hspace*{-1.7mm}$j \in \mathrm{U}_i^m$
\end{subnumcases}

\section{Game Formulation}
We model the interaction between MPO and ASPs as a two-stage single-leader-multi-followers Stackelberg game to capture the intrinsic hierarchy between MPO and ASPs and the influence between ASPs in the competition for the VMs.

In the proposed Stackelberg game, the MPO first decides the price per VM $\Psi_{m}^v$, and then the ASPs determine how many VMs to buy from MPO $z_i^v \, \forall i$. The MPO's selection of price per VM affects how many VMs those ASPs would buy, which in turn has an impact on the profit of the MPO. %Since the ASPs need to buy the computation resources from MPO to maintain their application services, the MPO has an advantage over the ASPs. 
Due to the finite number of available VMs offered by the MPO, the number of VMs one ASP can buy is influenced by the decisions of other ASPs. % The Stackelberg game where the MPO acts as the leader and all ASPs are the followers can capture the coupled and hierarchical relationship between MPO and ASPs, the self-interests of both MPO and ASPs, and the implicit influence among ASPs. 
We illustrate the actions and utilities of MPO and ASPs in the following first and then formally formulate the optimization problems for each player.

\subsection{The Action and The Utility of ASPs}
Given the MPO's price per VM $\Psi_m^v$, each ASP $i$ decides the number of VMs to buy from the MPO $z_i^v$ to maximize its profit, which is the revenue accrued from the NU $j \in \mathrm{U}_i^n$ minus the payment to the MPO for purchasing $z_i^v$ VMs. 
%The natural candidate for the utility is the profit. However, even with the same $z_i^v$, the revenue of ASP $i$ hinges on how many VMs it dedicates to the IPS, distribution of latency requirements $d_{ij}$, and the different payments of heterogeneous NU $j \in \mathrm{U}_i^n$. 
We define the utility of ASP $i$ when it purchases $z_i^v$ VMs from MPO as the maximum expected profit across the different number of VMs dedicates to the IPS $z_i^h$ with respect to the distribution of latency requirement $d_{ij}$. We assume that the latency requirements $d_{ij} \, \forall j \in \mathrm{U}_i$ of NUs served by ASP $i$ follow the uniform distribution over the interval $[a_i, b_i]$ denoted by $\mathcal{U}(a_i,b_i)$. %We further relax the variables of ASPs $z_i^v, z_i^h \, \forall i \in \mathcal{I}$ to real numbers. 
The utility of ASP $i$ given $\Psi_m^v$ is
\begin{align}
&Y_i(z_i^v|\Psi_m^v) \triangleq \max_{z_i^h} \mathsf{E}_{d_{ij}}\Big[\sum_{j \in \mathrm{U}_i^n} \mathcal{K}_{ij}(z_i^v, z_i^h) - \Psi_m^v z_i^v\Big] \\
&\hspace*{-1mm}=\max_{z_i^h} [\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_i^p(z_i^v, z_i^h)-a_i}{b_i-a_i}) - \Psi_m^vz_i^v] \label{eqn:asp_def_subobjective_unfold} \\
&\hspace*{-1mm}\triangleq \max_{z_i^h} X_i(z_i^h|z_i^v,\Psi_m^v) \label{eqn:asp_def_subobjective}
\end{align}
$\mathsf{E}_{d_{ij}}$ means taking expectation with respect to the distribution of $d_{ij}$.
%, and $\mathds{1}\{\cdot\}$ is the indicator function.
Given $z_i^v$, we have two constraints on $z_i^h$. First, the number of VMs dedicated to IPS $z_i^h$ must be no larger than the number of purchased VMs $z_i^v$. Second, the mean service rate by the VMs dedicated to running the service must be higher than the mean arrival rate for EUs $j \in \mathrm{U}_i$ for a stable processing queue. To define the utility of ASP $i$ when the purchased VMs from the MPO is $z_i^v$, we have to solve the following optimization problem.
\begin{maxi!}[2]
  {z_i^h \in \mathbb{R}}
  {X_i(z_i^h|z_i^v,\Psi_m^v) \label{eqn:asp_utility_def_opti_obj}}
  {\label{eqn:asp_utility_def_opti}}
  {}
  \addConstraint{0 \leq z_i^h \leq \xi_i z_i^v}{\label{eqn:asp_utility_def_opti_const1}}
  \addConstraint{0 < (z_i^v-z_i^h)\mu_i^v - \lambda_i + H(z_i^h) }{\label{eqn:asp_utility_def_opti_const2}}
\end{maxi!}
In (\ref{eqn:asp_utility_def_opti_const1}), we introduce $\xi_i\in[0, 1]$ as the upper bound of $z_i^h$ to reserve computation resource for basic service. Similarly, in (\ref{eqn:asp_utility_def_opti_const2}), the service rate must exceed the arrival rate to make the queue stable.
%we use another system parameter $\phi_i$ to specify the quantity by which the mean service rate must exceed the mean arrival rate. %The observation that both (\ref{eqn:asp_utility_def_opti_const1}) and (\ref{eqn:asp_utility_def_opti_const2}) impose upper bounds on the range of $z_i^h$ will simplify the characterization of the optimal $z_i^h$. 
Showing the utility of the ASP $i$, $Y_i(z_i^v)$, is well-defined is equivalent to proving the optimization problem (\ref{eqn:asp_utility_def_opti}) has at least one solution, which can be proved by showing it is a convex optimization problem. The proof is omitted due to the page limitation.
%If there are multiple optimal points that have the same values of $X_i(z_i^h|z_i^v,\Psi_m^v)$, we randomly select one to be the solution to (\ref{eqn:asp_utility_def_opti}).
% Comment Out
\iffalse
\begin{lemma}
The utility of ASP $i$, $Y_i(z_i^v)$, is well defined. That is, the optimization problem (\ref{eqn:asp_utility_def_opti}) has at least one optimal point. Moreover, the optimization problem (\ref{eqn:asp_utility_def_opti}) is a convex optimization problem. 
\end{lemma}



\begin{proof}
The feasible region imposed by (\ref{eqn:asp_utility_def_opti_const1}) and (\ref{eqn:asp_utility_def_opti_const2}) is a closed and bounded interval in $\mathbb{R}$ and thus is a convex set. As the objective function (\ref{eqn:asp_utility_def_opti_obj}) is continuous in $z_i^h$, the existence of the optimal solution then comes from the Extreme Value Theorem. If (\ref{eqn:asp_utility_def_opti_obj}) is concave at each feasible $z_i^h$, optimization problem (\ref{eqn:asp_utility_def_opti}) is a convex optimization problem. It remains to show that the objective function (\ref{eqn:asp_utility_def_opti_obj}) is concave in feasible $z_i^h$. By rearranging the terms, we express $X_i(z_i^h|z_i^v,\Psi_m^v)$ as
\begin{equation}
\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t -a_i}{b_i-a_i})- \Psi_m^v z_i^v - \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(\frac{T_i^p(z_i^v, z_i^h)}{b_i-a_i})
\end{equation}
 To show $X_i(z_i^h|z_i^v,\Psi_m^v)$ is concave in feasible $z_i^h$, it suffices to show that $T_i^p(z_i^v, z_i^h)$ is convex in feasible $z_i^h$. We verity the concavity of $T_i^p(z_i^v, z_i^h)$ by taking second derivative with respect to $z_i^h$.
\begin{subequations}\label{eqn:asp_subobjective_second_deriv}
     \begin{alignat}{1}
       &[(z_i^v- z_i^h)\mu_i^v - \lambda_i + H(z_i^h)]^{-3} \cdot [-\mu_i^v+H'(z_i^h)]^2 \label{eqn:asp_subobjective_second_deriv_first_term} \\
       &+ (-1) \cdot [(z_i^v-z_i^h)\mu_i^v - \lambda_i + H(z_i^h)]^{-2} \cdot H''(z_i^h) \label{eqn:asp_subobjective_second_deriv_second_term}
     \end{alignat}
\end{subequations}
$H'(z_i^h)$ and $H''(z_i^h)$ stand for first and second derivative with respect to $z_i^h$. In (\ref{eqn:asp_subobjective_second_deriv_first_term}) and (\ref{eqn:asp_subobjective_second_deriv_second_term}), $(z_i^v- z_i^h)\mu_i^v - \lambda_i - H(z_i^h)$ is always positive at each feasible $z_i^h$ because of (\ref{eqn:asp_utility_def_opti_const2}). Also, as $H(\cdot)$ is concave, $H''(z_i^h)$ is non-positive. Therefore, (\ref{eqn:asp_subobjective_second_deriv_first_term}) and (\ref{eqn:asp_subobjective_second_deriv_second_term}) are non-negative. We can conclude that the second derivative of $T_i^p(z_i^v, z_i^h)$ is non-negative, and $T_i^p(z_i^v, z_i^h)$ is convex in feasible $z_i^h$.
\end{proof}
\fi
%Comment Out
We then formulate the optimization problem of ASP $i$ given the MPO's price per VM $\Psi_m^v$.
\begin{maxi!}[2]
  {z_i^v \in \mathbb{R}}
  {Y_i(z_i^v|\Psi_m^v) \label{eqn:asp_utility_opti_obj}}
  {\label{eqn:asp_utility_opti}}
  {}
  \addConstraint{\lambda_i+ \gamma_i \leq z_i^v \mu_i^v}{\label{eqn:asp_utility_opti_const1}}
  \addConstraint{0 \leq Y_i(z_i^v|\Psi_m^v)}{\label{eqn:asp_utility_opti_const2}}
\end{maxi!}
The constraint (\ref{eqn:asp_utility_opti_const1}) regulates that when the ASP $i$ dedicates all purchased VMs to running the application service, the mean service rate must be larger than the mean arrival rate by at least $\gamma_i$, where $\gamma_i\geq 0$, as reserve computation resources for IPS.% (\ref{eqn:asp_utility_opti_const1}) also ensures that the feasible region of (\ref{eqn:asp_utility_def_opti}) is non-empty because under this constraint, there is at least one $z_i^h$ that satisfies (\ref{eqn:asp_utility_def_opti_const2}). 
The constraint (\ref{eqn:asp_utility_opti_const2}) represents the individual rationality for every ASP. That is, when making the processing queue stable gives a negative utility, the ASPs would rather choose to end its service and receive zero utility. %We defer the analysis of solutions to both optimization problems (\ref{eqn:asp_utility_def_opti}) and (\ref{eqn:asp_utility_opti}) to the \Cref{sec:game_optimization}. 
We denote the solution to (\ref{eqn:asp_utility_opti}) as $(z_i^v(\Psi_m^v))^*$ to emphasize the dependence on the MPO's price per VM $\Psi_m^v$.

\subsection{The Action and The Utility of The MPO}
%With the prediction about the number of VMs purchased by ASPs $(z_i^v(\Psi_m^v))^* \, \forall i \in \mathcal{I}$, 
The MPO chooses the price per VM $\Psi_m^v$ to maximize its utility which is defined as the MPO's profit, which is its revenue minus the operating cost of the deployed VMs. The revenue of the MPO is the sum of payments from all ASPs. %Although the ASPs buy the VMs from the MPO, it is the infrastructure of the MPO that processes the application requests. 
The cost for operating $\sum_{i \in \mathcal{I}} (z_i^v(\Psi_m^v))^*$ VMs is denoted as $C_m^v\big(\sum_{i \in \mathcal{I}} (z_i^v(\Psi_m^v))^*\big)$. The function $C_m^v(\cdot)$ is assumed to be convex and non-decreasing.%, which means that both the marginal cost and the cost increase as the number of VMs that the MPO has to keep running increases. 
We then denote the MPO's utility as $Y_m(\Psi_m^v)$ and formulate the MPO's optimization problem.
\begin{maxi!}[2]
  {\Psi_m^v \in 0 \cup \mathbb{R}^{+}}
  {\Psi_m^v \cdot \sum_{i \in \mathcal{I}} (z_i^v(\Psi_m^v))^* - C_m^v\big(\sum_{i \in \mathcal{I}} (z_i^v(\Psi_m^v))^*\big) \label{eqn:mpo_utility_opti_obj}}
  {\label{eqn:mpo_utility_opti}}
  {}
  \addConstraint{\sum_{i \in \mathcal{I}} (z_i^v(\Psi_m^v))^* \leq \mathcal{Q}_v}{\label{eqn:mpo_utility_opti_const1}}
\end{maxi!}
The constraint (\ref{eqn:mpo_utility_opti_const1}) mandates the maximum number of available VMs. The constraint (\ref{eqn:mpo_utility_opti_const1}) imposes a lower bound for MPO's price per VM. %The property of this optimization (\ref{eqn:mpo_utility_opti}) relies on the solution $(z_i^v(\Psi_m^v))^*$, and we defer the analysis to \Cref{sec:game_optimization}.

\section{Stackelberg Equilibrium} \label{sec:game_optimization}
We would leverage the backward induction principle to solve the formulated Stackelberg game to find the Stackelberg equilibrium. In this principle, we solve the followers' (ASPs') optimization problems first and then the leader's (MPO's) optimization problem based on responses of ASPs to the MPO's price per VM, i.e., $(z_i^v(\Psi_m^v))^* \, \forall i \in \mathcal{I}$. %We analyze the ASP Optimization problem according to whether the solution to (\ref{eqn:asp_utility_def_opti}) is the extreme point or boundary point of the constraint.

% Comment Out
\iffalse
Before delving into the solution process, we first define the Stackelberg game equilibrium. We symbolize the ASP $i$'s action set using $\mathcal{A}_i$ and the profile of all ASPs' action using $\bm{z^v}=(z_1^v, z_2^v, \cdots, z_I^v) \in \mathcal{A}_1 \times \mathcal{A}_2 \cdots \times \mathcal{A}_I$ where $\mathcal{A}_1 \times \mathcal{A}_2$ means the Cartesian product of $\mathcal{A}_1$ and $\mathcal{A}_2$. The ASP $i$'s best response set $\mathcal{B}_i^R(\Psi_m^v)$ to the MPO's price per VM $\Psi_m^v$ is given by
\begin{equation} \label{eqn:asp_best_response}
\begin{aligned}
\mathcal{B}_i^R(\Psi_m^v) = &\{z_i^v \in \mathcal{A}_i |Y_i(z_i^v|\Psi_m^v) \geq Y_i\big((z_i^v)'|\Psi_m^v\big) \\
&\forall (z_i^v)' \in \mathcal{A}_i, (z_i^v)' \neq z_i^v\}
\end{aligned}
\end{equation}
We also denote the Cartesian product of all ASPs' best response sets as
\begin{equation}
\mathcal{B}^R(\Psi_m^v) = \mathcal{B}_1^R(\Psi_m^v) \times \mathcal{B}_2^R(\Psi_m^v) \cdots \times \mathcal{B}_I^R(\Psi_m^v)
\end{equation}
Likewise, we denote the MPO's action set as $\mathcal{A}_m$. Furthermore, to stress the influence of ASPs' actions on the MPO's utility, we use $Y_m(\Psi_m^v|\bm{z^v})$ to represent the MPO's utility in the following definition of the MPO's best response set.
\begin{equation} \label{eqn:mpo_best_response}
\begin{aligned}
\mathcal{B}_m = &\{\Psi_m^v \in \mathcal{A}_m| Y_m(\Psi_m^v|\bm{z^v}) \geq Y_m((\Psi_m^v)'|(\bm{z^v})') \\
&\forall (\Psi_m^v)' \in \mathcal{A}_m, (\Psi_m^v)' \neq \Psi_m^v, \forall \bm{z^v} \in \mathcal{B}^R(\Psi_m^v) \\
&\forall  (\bm{z^v})' \in \mathcal{B}^R\big((\Psi_m^v)'\big)\}
\end{aligned}
\end{equation}
\begin{definition}[\textbf{Stackelberg equilibrium}] \label{def:stackelberg_equilibrium}
If $\mathcal{B}_{m}$ and $\mathcal{B}^R(\Psi_m^v)$ are both non-empty, the Stackelberg equilibrium in our mechanism is a vector of dimension $(I+1)$ that is an element of $\mathcal{B}_m  \times \mathcal{B}^R(\Psi_m^v)$.
\end{definition}


We analyze the solution process of the formulated Stackelberg game according to whether the solution to (\ref{eqn:asp_utility_def_opti}) is the extreme point or boundary point of the constraint.
\fi
% Comment Out

\subsection{ASP Optimization Problem}
We analyze the solution process of the formulated Stackelberg game according to whether the solution to (\ref{eqn:asp_utility_def_opti}) is at the extreme point or boundary point of the constraint.

\textbf{Case 1}: The optimal point of (\ref{eqn:asp_utility_def_opti}) is the extreme point whose first derivative with respect to $z_i^h$ equals zero. 

% Comment Out 


\iffalse
\begin{equation} \label{eqn:asp_utilitu_def_firstderiv}
[(z_i^v - z_i^h) - \lambda_i + H(z_i^h)]^{-2} \cdot (-\mu_i^v + H'(z_i^h))
\end{equation}
$(z_i^v - z_i^h) - \lambda_i + H(z_i^h)$ is positive at every feasible $z_i^h$ because of the constraint (\ref{eqn:asp_utility_def_opti_const2}). Also, $H'(\cdot)$ is non-decreasing and thus has an inverse function denoted by $G(\cdot)$. We can solve the extreme point denoted by $(z_i^h)^*$ through letting (\ref{eqn:asp_utilitu_def_firstderiv}) equal zero.
\begin{equation} \label{eqn:asp_utility_def_extreme_point}
(z_i^h)^* = (H')^{-1}(\mu_i^v) \triangleq G(\mu_i^v)
\end{equation}
When we substitute (\ref{eqn:asp_utility_def_extreme_point}) into (\ref{eqn:asp_mm1_delay}), the mean processing delay denoted as $T_{i,1}^p(z_i^v)$ depends only on $z_i^v$ and is
\begin{equation}
T_{i,1}^p(z_i^v) = \frac{1}{\big(z_i^v - G(\mu_i^v)\big)\mu_i^v - \lambda_i + H\big(G(\mu_i^v)\big)}
\end{equation}
According to (\ref{eqn:asp_def_subobjective_unfold}) and (\ref{eqn:asp_def_subobjective}), the (\ref{eqn:asp_utility_opti_obj}) becomes
\begin{equation}\label{eqn:asp_case1_utility}
Y_i^1(z_i^v|\Psi_m^v) \triangleq \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_{i,1}^p(z_i^v)-a_i}{b_i-a_i}) - \Psi_m^vz_i^v
\end{equation}

If we optimize (\ref{eqn:asp_case1_utility}), we can observe how the ASP reacts to different $z_i^v$ and $\Psi_m^v$ in order to reach the highest utility.
\fi
 % Comment Out
However, this case doesn't happen with $H(x) = \eta{x}$. %The proof is omitted due to page limitation.
We explain the property in the following lemma.
% Comment Out


\begin{lemma} \label{lemma:asp_case1_not_exist}
$X_i(z_i^h|z_i^v,\Psi_m^v)$ doesn't have extreme point in feasible $z_i^h$ if $H(x) = \eta{x}$. 
\end{lemma}


% Comment Out

\begin{proof}
The derivative of $X_i(z_i^h|z_i^v,\Psi_m^v)$ with respect to $z_i^h$ is
%From (\ref{eqn:asp_utilitu_def_firstderiv}),  we substitute $\eta{z_i^h}$ into $H(z_i^h)$, then we can obtain
\begin{equation} \label{eqn:asp_utilitu_simplified}
[(z_i^v - z_i^h) - \lambda_i + \eta{z_i^h}]^{-2} \cdot (-\mu_i^v + \eta)
\end{equation}
Obviously, no matter what the value of $z_i^h$ is, (\ref{eqn:asp_utilitu_simplified}) equaling zero will never be satisfied. Therefore, the extreme point of (\ref{eqn:asp_utility_def_opti_obj}) does not exist in feasible $z_i^h$, so the maximum value of $X_1(z_i^h|z_i^v,\Psi_m^v)$ only happens at the boundary points.
\qedhere
\end{proof}

% Comment Out

\textbf{Case 2}: The optimal point of (\ref{eqn:asp_utility_def_opti}) happens at the right boundary of (\ref{eqn:asp_utility_def_opti_const1}). That is, the ASP $i$'s optimal number of VMs devoted to the IPS is
\begin{equation} \label{eqn:asp_utility_def_first_boundary}
(z_i^h)^* = \xi_i z_i^v
\end{equation}
When we substitute (\ref{eqn:asp_utility_def_first_boundary}) into (\ref{eqn:asp_mm1_delay}), the mean processing delay in this case denoted as $T_{i,2}^p(z_i^v) = [(1-\xi_i)z_i^v\mu_i^v - \big(\lambda_i - H(\xi_iz_i^v)\big)]^{-1}$
\iffalse
\begin{equation} \label{eqn:asp_case2_mm1_delay}
T_{i,2}^p(z_i^v) =  \frac{1}{(1-\xi_i)z_i^v\mu_i^v - \big(\lambda_i - H(\xi_iz_i^v)\big)}
\end{equation}
\fi
According to (\ref{eqn:asp_def_subobjective_unfold}) and (\ref{eqn:asp_def_subobjective}), the objective function (\ref{eqn:asp_utility_opti_obj}) becomes
\begin{equation} \label{eqn:asp_case2_objective}
Y_i^2(z_i^v|\Psi_m^v) \triangleq \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_{i,2}^p(z_i^v)-a_i}{b_i-a_i}) - \Psi_m^vz_i^v
\end{equation}

% Comment Out
\iffalse
We prove this properties in the following.
\begin{lemma} \label{lemma:asp_case2_utility_concave}
$Y_i^2(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$.
\end{lemma}
\begin{proof}
If $T_{i,2}^p(z_i^v)$ is convex in feasible $z_i^v$, $Y_i^2(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$. We can verify the convexity of $T_{i,2}^p(z_i^v)$ by taking second derivative of $T_{i,2}^p(z_i^v)$ with respect to $z_i^v$.
\begin{equation} \label{eqn:asp_case2_mm1_delay_second_deriv}
\begin{aligned}
&2[(1-\xi_i)\mu_i^v z_i^v - \lambda_i + H(\xi_i z_i^v)]^{-3}\times [(1-\xi_i)\mu_i^v\\
&+ \xi_i H'(\xi_i z_i^v)]^2-[(1-\xi_i)\mu_i^v z_i^v - \lambda_i + H(\xi_i z_i^v)]^{-2}  \\
& \times (\xi_i)^2 H''(\xi_i z_i^v)
\end{aligned}{}
\end{equation}
Since $(z_i^h)^* = \xi_i z_i^v$ satisfies the constraint (\ref{eqn:asp_utility_def_opti_const2}), $(1-\xi_i)\mu_i^v z_i^v - \lambda_i + H(\xi_i z_i^v)$ is always positive. Moreover, as $H(\cdot)$ is concave, $H''(\xi_i z_i^v)$ is non-positive. The first term of (\ref{eqn:asp_case2_mm1_delay_second_deriv}) is positive, and the second term of (\ref{eqn:asp_case2_mm1_delay_second_deriv}) is non-positive. Therefore, (\ref{eqn:asp_case2_mm1_delay_second_deriv}) is non-negative, which means $T_{i,2}^p(z_i^v)$ is convex in feasible $z_i^v$. Hence, $Y_i^2(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$. \qedhere
\end{proof}
With \Cref{lemma:asp_case2_utility_concave}, 
\fi
% Comment Out

We can characterize the solution to the optimization problem (\ref{eqn:asp_utility_opti}) when the objective function (\ref{eqn:asp_utility_opti_obj}) equals $Y_i^2(z_i^v|\Psi_m^v)$ in the following theorem with a specific form of $H(\cdot)$. Before stating the result, we define the feasible region of (\ref{eqn:asp_utility_opti_const1}) as $\Upsilon_i$ for ASP i while the feasible region of (\ref{eqn:asp_utility_opti_const2}) as $\Upsilon_i^2$ when the $Y_i(z_i^v|\Psi_m^v)$ equals $Y_i^2(z_i^v|\Psi_m^v)$.
\begin{theorem}\label{thm:asp_case2_optimal}
The solution to the optimization problem (\ref{eqn:asp_utility_opti}) when the objective function (\ref{eqn:asp_utility_opti_obj}) equals $Y_i^2(z_i^v|\Psi_m^v)$ and $H(x)=\eta x$ is $(z_{i,2}^v(\Psi_m^v))^*$, if $\Upsilon_i \cap \Upsilon_i^2 \neq \emptyset $
\begin{subnumcases}{=\label{eqn:asp_case2_optimal_solution}}
  \frac{\lambda_i+\gamma_i}{\mu_i^v} & $(z_{i,2}^{v,e}(\Psi_m^v))^* < \frac{\lambda_i+\gamma_i}{\mu_i^v}$ \label{eqn:asp_case2_optimal_solution_lower_boundary} \\
  (z_{i,2}^{v,e}(\Psi_m^v))^* & $(z_{i,2}^{v,e}(\Psi_m^v))^* \geq \frac{\lambda_i+\gamma_i}{\mu_i^v}$ \label{eqn:asp_case2_optimal_solution_extreme}
\end{subnumcases}
where
\begin{equation}\label{eqn:asp_case2_utility_extreme}
\begin{aligned}
(z_{i,2}^{v,e}(\Psi_m^v))^* &= \sqrt{\frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{(b_i-a_i)\Psi_m^v [(1-\xi_i)\mu_i^v + \xi_i \eta]}} \\
&+ \frac{\lambda_i}{(1-\xi_i)\mu_i^v + \xi_i \eta}
\end{aligned}
\end{equation}
and if $\Upsilon_i \cap \Upsilon_i^2 = \emptyset$
\begin{equation}\label{eqn:asp_case2_optimal_solution_individual_rationality}
\begin{aligned}
    (z_{i,2}^{v}(\Psi_m^v))^*=0
\end{aligned}
\end{equation}
\end{theorem}
The proof is omitted due to page limitation. A sketch of the proof is that we can first show that $Y_i^2(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$. Then, we show the feasible region is a convex set. Finally, we provide case-by-case discussions to show the optimal solution in each sub-region.

% Comment Out
\iffalse
\begin{proof}
We begin by proving the feasible region is a convex set. $\Upsilon_i$ is a convex set because $\Upsilon_i$ is a ray starting from $\frac{\lambda_i+\gamma_i}{\mu_i^v}$ to $\infty$. Since we have proved the convexity of $Y_i^2(z_i^v|\Psi_m^v)$ in \Cref{lemma:asp_case2_utility_concave}, $\Upsilon_i^2$ is a convex set because any superlevel set of a concave function is a convex set. Since the intersection of two convex set is a convex set, $\Upsilon_i \cap \Upsilon_i^2$ is a convex set. When $\Upsilon_i \cap \Upsilon_i^2 = \emptyset$, which means the ASP $i$ cannot make the processing queue stable while has a positive utility no matter how many VMs ASP $i$ buys from the MPO. In this situation, the best action of ASP $i$ is not to buy any VM. By \Cref{lemma:asp_case2_utility_concave}, $Y_i^2(z_i^v|\Psi_m^v)$ is concave. When the extreme point of $Y_i^2(z_i^v|\Psi_m^v)$ is smaller than $\frac{\lambda_i+\gamma_i}{\mu_i^v}$, $\frac{\lambda_i+\gamma_i}{\mu_i^v}$ is the optimal point. When the extreme point of $Y_i^2(z_i^v|\Psi_m^v)$ falls in the interior of the feasible region, the extreme point is the optimal point. The extreme point of $Y_i^2(z_i^v|\Psi_m^v)$ can be solved when the first derivative of $Y_i^2(z_i^v|\Psi_m^v)$ with respect to $z_i^v$ equals zero.
\begin{equation} \label{eqn:asp_case2_utility_first_deriv}
-\frac{\partial T_{i,2}^p(z_i^v)}{\partial z_i^v} = \frac{\Psi_m^v (b_i - a_i)}{\sum_{j \in \mathsf{U}_i^n} \Psi_{ij}}
\end{equation}
Using (\ref{eqn:asp_case2_mm1_delay}), (\ref{eqn:asp_case2_objective}), and $H(x)=\eta x$, it only takes simple algebraic operations to have the expression for the extreme point in (\ref{eqn:asp_case2_utility_extreme}). \qedhere
\end{proof}
\fi
% Comment Out

From \Cref{thm:asp_case2_optimal}, we can obtain the MPO's price per VM $\Psi_m^i$ which makes the ASP $i$'s optimal response switch among (\ref{eqn:asp_case2_optimal_solution_individual_rationality}), (\ref{eqn:asp_case2_optimal_solution_lower_boundary}) and (\ref{eqn:asp_case2_optimal_solution_extreme})by solving the $\Psi_m^v$ that satisfies $Y_i^2(\frac{\lambda_i+\gamma_i}{\mu_i^v}|\Psi_m^v) = 0$ and $(z_{i,2}^{v,e}(\Psi_m^v))^* = \frac{\lambda_i+\gamma_i}{\mu_i^v}$.
\begin{equation}
\begin{aligned}
\Psi_{m,2}^{i,z}&= \frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{(b_i-a_i)[(1-\xi_i)\mu_i^v + \xi_i \eta]} \\
& \times \big[\frac{\lambda_i+\gamma_i}{\mu_i^v} - \frac{\lambda_i}{(1-\xi_i)\mu_i^v + \xi_i\eta}\big]^{-2}
\end{aligned}
\end{equation}.
\begin{equation}
\begin{aligned}
\Psi_{m,2}^{i,l}&= \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_{i,2}^p(\frac{\lambda_i+\gamma_i}{\mu_i^v})-a_i}{b_i-a_i})\times(\frac{\mu_i^v}{\lambda_i+\gamma_i})
\end{aligned}
\end{equation}
\iffalse
% Comment Out

The $z_i^v$ will switch from $0$ to $\frac{\lambda_i+\gamma_i}{\mu_i^v}$ at $\Psi_{m,2}^{i,z}$ and $\frac{\lambda_i+\gamma_i}{\mu_i^v}$ to$(z_{i,2}^{v,e}(\Psi_m^v))^*$ at $\Psi_{m,2}^{i,l}$.
\fi

\textbf{Case 3}: The optimal point of (\ref{eqn:asp_utility_def_opti}) happens at the left boundary of (\ref{eqn:asp_utility_def_opti_const1}). That is, when the purchased number of VM is $z_i^v$, the ASP $i$'s optimal number of VMs devoted to the IPS $(z_i^h)^*$ is
\begin{equation} \label{eqn:asp_utility_def_first_boundary_2}
(z_i^h)^* = 0
\end{equation}
When we substitute (\ref{eqn:asp_utility_def_first_boundary_2}) into (\ref{eqn:asp_mm1_delay}), the mean processing delay denoted as $T_{i,3}^p(z_i^v) = [z_i^v \mu_i^v-\lambda_i]^{-1}$

\iffalse
\begin{equation}\label{eqn:asp_case3_mm1_delay}
T_{i,3}^p(z_i^v) = \frac{1}{z_i^v \mu_i^v-\lambda_i}
\end{equation}
\fi
According to (\ref{eqn:asp_def_subobjective_unfold}) and (\ref{eqn:asp_def_subobjective}), the objective function (\ref{eqn:asp_utility_opti_obj}) becomes
\begin{equation}\label{eqn:asp_case3_objective}
Y_i^3(z_i^v|\Psi_m^v) \triangleq \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_{i,3}^p(z_i^v)-a_i}{b_i-a_i}) - \Psi_m^vz_i^v
\end{equation}
%If $Y_i^3(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$, it is much easier to solve the optimization problem (\ref{eqn:asp_utility_opti}) with the objective being $Y_i^3(z_i^v|\Psi_m^v)$. The proof of convexity is omitted due to page limitation.

% Comment Out
\iffalse
We prove this properties in the following.
\begin{lemma} \label{lemma:asp_case3_utility_concave}
$Y_i^3(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$.
\end{lemma}
\begin{proof}
If $T_{i,3}^p(z_i^v)$ is convex in feasible $z_i^v$, $Y_i^3(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$. We can verify the convexity of $T_{i,3}^p(z_i^v)$ by taking second derivative of $T_{i,3}^p(z_i^v)$ with respect to $z_i^v$.

\begin{equation} \label{eqn:asp_case3_mm1_delay_second_deriv}
\begin{aligned}
&[2(\mu_i^v)^2](z_i^v\mu_i^v-\lambda_i)^{-2}
\end{aligned}
\end{equation}
The first term of (\ref{eqn:asp_case3_mm1_delay_second_deriv}) is positive. Moreover, $(z_i^v)\mu_i^v - \lambda_i$ is larger than $0$ to satisfy the constraint (\ref{eqn:asp_utility_def_opti_const1}), so the second term of (\ref{eqn:asp_utility_def_opti_const1}) is always positive. Therefore, (\ref{eqn:asp_case3_mm1_delay_second_deriv}) is non-negative, which means $T_{i,3}^p(z_i^v)$ is convex in feasible $z_i^v$. Hence, $Y_i^3(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$. \qedhere
\end{proof}
With \Cref{lemma:asp_case3_utility_concave}, 
\fi
% Comment Out

Similarly, We can characterize the solution to the optimization problem (\ref{eqn:asp_utility_opti}) when the objective function (\ref{eqn:asp_utility_opti_obj}) equals $Y_i^3(z_i^v|\Psi_m^v)$ in the following theorem with a specific form of $H(\cdot)$. Similarly in Case 2, we define the feasible region of (\ref{eqn:asp_utility_opti_const2}) as $\Upsilon_i^3$ when the $Y_i(z_i^v|\Psi_m^v)$ equals $Y_i^3(z_i^v|\Psi_m^v)$.
\begin{theorem}\label{thm:asp_case3_optimal}
The solution to the optimization problem (\ref{eqn:asp_utility_opti}) when the objective function (\ref{eqn:asp_utility_opti_obj}) equals $Y_i^3(z_i^v|\Psi_m^v)$ and $H(x)=\eta x$ is $(z_{i,3}^v(\Psi_m^v))^*$ and if $\Upsilon_i \cap \Upsilon_i^3 \neq \emptyset $
\begin{subnumcases}{=\label{eqn:asp_case3_optimal_solution}}
  \frac{\lambda_i+\gamma_i}{\mu_i^v} & $(z_{i,3}^{v,e}(\Psi_m^v))^* < \frac{\lambda_i+\gamma_i}{\mu_i^v}$ \label{eqn:asp_case3_optimal_solution_lower_boundary} \\
  (z_{i,3}^{v,e}(\Psi_m^v))^* & $(z_{i,3}^{v,e}(\Psi_m^v))^* \geq \frac{\lambda_i+\gamma_i}{\mu_i^v}$ \label{eqn:asp_case3_optimal_solution_extreme}
\end{subnumcases}
where
\begin{equation}\label{eqn:asp_case3_utility_extreme}
\begin{aligned}
(z_{i,3}^{v,e}(\Psi_m^v))^* &= \sqrt{\frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{\mu_i^v(b_i-a_i)\Psi_m^v}} + \frac{\lambda_i}{\mu_i^v}
\end{aligned}
\end{equation}
and if $\Upsilon_i \cap \Upsilon_i^3 = \emptyset$
\begin{equation} \label{eqn:asp_case3_optimal_solution_individual_rationality}
\begin{aligned}
    (z_{i,3}^{v}(\Psi_m^v))^*=0
\end{aligned}
\end{equation}
\end{theorem}
The proof follows the same flow as of \Cref{thm:asp_case2_optimal}.% and is omitted.

% Comment Out
\iffalse
\begin{proof}
We begin by proving the feasible region is a convex set. $\Upsilon_i$ is a convex set because $\Upsilon_i$ is a ray starting from $\frac{\lambda_i+\gamma_i}{\mu_i^v}$ to $\infty$. Since we have proved the convexity of $Y_i^3(z_i^v|\Psi_m^v)$ in \Cref{lemma:asp_case3_utility_concave}, $\Upsilon_i^3$ is a convex set because any superlevel set of a concave function is a convex set. Since the intersection of two convex set is a convex set, $\Upsilon_i \cap \Upsilon_i^3$ is a convex set. When $\Upsilon_i \cap \Upsilon_i^3 = \emptyset$, which means the ASP $i$ cannot make the processing queue stable while has a positive utility no matter how many VMs ASP $i$ buys from the MPO. In this situation, the best action of ASP $i$ is not to buy any VM. By \Cref{lemma:asp_case3_utility_concave}, $Y_i^3(z_i^v|\Psi_m^v)$ is concave. When the extreme point of $Y_i^3(z_i^v|\Psi_m^v)$ is smaller than $\frac{\lambda_i+\gamma_i}{\mu_i^v}$, $\frac{\lambda_i+\gamma_i}{\mu_i^v}$ is the optimal point. When the extreme point of $Y_i^3(z_i^v|\Psi_m^v)$ falls in the interior of the feasible region, the extreme point is the optimal point. The extreme point of $Y_i^2(z_i^v|\Psi_m^v)$ can be solved when the first derivative of $Y_i^3(z_i^v|\Psi_m^v)$ with respect to $z_i^v$ equals zero.
\begin{equation} \label{eqn:asp_case3_utility_first_deriv}
-\frac{\partial T_{i,3}^p(z_i^v)}{\partial z_i^v} = \frac{\Psi_m^v (b_i - a_i)}{\sum_{j \in \mathsf{U}_i^n} \Psi_{ij}}
\end{equation}
Using (\ref{eqn:asp_case3_mm1_delay}), (\ref{eqn:asp_case3_objective}), and $H(x)=\eta x $, it only takes simple algebraic operations to have the expression for the extreme point in (\ref{eqn:asp_case3_utility_extreme}). \qedhere
\end{proof}
\fi
% Comment Out

From \Cref{thm:asp_case3_optimal}, we can obtain the MPO's price per VM $\Psi_m^i$ which makes the ASP $i$'s optimal response switch among (\ref{eqn:asp_case3_optimal_solution_individual_rationality}), (\ref{eqn:asp_case3_optimal_solution_lower_boundary}) and (\ref{eqn:asp_case3_optimal_solution_extreme}) by solving the $\Psi_m^v$ that satisfies $Y_i^3(\frac{\lambda_i+\gamma_i}{\mu_i^v}|\Psi_m^v) = 0$ and $(z_{i,3}^{v,e}(\Psi_m^v))^* = \frac{\lambda_i+\gamma_i}{\mu_i^v}$.
\begin{equation}
\begin{aligned}
\Psi_{m,3}^{i,z}&= \frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{(b_i-a_i)}\times \big[\frac{\lambda_i+\gamma_i}{\mu_i^v} - \frac{\lambda_i}{\mu_i^v}\big]^{-2}
\end{aligned}
\end{equation}.
\begin{equation}
\begin{aligned}
\Psi_{m,3}^{i,l}&= \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_{i,3}^p(\frac{\lambda_i+\gamma_i}{\mu_i^v})-a_i}{b_i-a_i})\times(\frac{\mu_i^v}{\lambda_i+\gamma_i})
\end{aligned}
\end{equation}




% Conment out
\iffalse
\textbf{Case 4}: The optimal point of (\ref{eqn:asp_utility_def_opti}) happens at the boundary of (\ref{eqn:asp_utility_def_opti_const2}). That is, when the purchased number of VM is $z_i^v$, the ASP $i$'s optimal number of VMs devoted to the IPS $(z_i^h)^*$ satisfies
\begin{equation} \label{eqn:asp_utility_def_second_boundary}
\phi_i z_i^v \mu_i^v = \big(z_i^v-(z_i^h)^*\big)\mu_i^v - \lambda_i + H\big((z_i^h)^*\big)
\end{equation}
When we substitute (\ref{eqn:asp_utility_def_second_boundary}) into (\ref{eqn:asp_mm1_delay}), the mean processing delay denoted as $T_{i,4}^p(z_i^v)$ depends only on $z_i^v$ and is
\begin{equation}\label{eqn:asp_case4_mm1_delay}
T_{i,4}^p(z_i^v) = \frac{1}{\phi_i z_i^v \mu_i^v}
\end{equation}
According to (\ref{eqn:asp_def_subobjective_unfold}) and (\ref{eqn:asp_def_subobjective}), the objective function (\ref{eqn:asp_utility_opti_obj}) becomes
\begin{equation}
Y_i^4(z_i^v|\Psi_m^v) \triangleq \sum_{j \in \mathrm{U}_i^n}\Psi_{ij}(1-\frac{T_{ij}^t + T_{i,4}^p(z_i^v)-a_i}{b_i-a_i}) - \Psi_m^vz_i^v
\end{equation}
If $Y_i^4(z_i^v|\Psi_m^v)$ is concave in feasible $z_i^v$, it is much easier to solve the optimization problem (\ref{eqn:asp_utility_opti}) with the objective being $Y_i^4(z_i^v|\Psi_m^v)$. However, we don't optimize $Y_i^4(z_i^v|\Psi_m^v)$ since the case doesn't happen. We prove this properties in the following.
\begin{lemma} \label{lemma:asp_case4_not_exist}
The optimal point of (\ref{eqn:asp_utility_def_opti}) never happens at the boundary of (\ref{eqn:asp_utility_def_opti_const2}) unless the boundary of (\ref{eqn:asp_utility_def_opti_const2}) is also the boundary of (\ref{eqn:asp_utility_def_opti_const1}).
\end{lemma}
\begin{proof}
Let's compare the value of (\ref{eqn:asp_case4_mm1_delay}) with the value of  (\ref{eqn:asp_case2_mm1_delay}) and (\ref{eqn:asp_case3_mm1_delay}) respectively.

\end{proof}
\begin{equation}
\begin{aligned}
\Psi_{m,3}^{i,l} = \frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{\phi_i \mu_i^v(b_i-a_i)}\big(\zeta_i^{3u}\big)^2 \\
\Psi_{m,3}^{i,u} = \frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{\phi_i \mu_i^v(b_i-a_i)}\big(\zeta_i^{3l}\big)^2 \\
\end{aligned}
\end{equation}
\fi
% Comment out



%Based on the analysis above, the MPO can predict how many VMs every ASP will buy given an arbitrary price per VM in each case, which make MPO can optimize its utility by setting $\Psi_m^v$. We will optimize the utility of MPO in the next subsection. 

\subsection{MPO Optimization Problem}
In this section, we solve the optimization problem (\ref{eqn:mpo_utility_opti}). For every ASP, the optimal solution is either Case 2 or Case 3, that is, $\mathcal{I}_{case2} \cup \mathcal{I}_{case3} = \mathcal{I}$, where $\mathcal{I}_{case2}$ indicates the ASP set which its optimal solution is in Case 2, and $\mathcal{I}_{case3}$ indicates the ASP set which its optimal solution is in Case 3. The boundary set of all ASP is $\{\Psi_{m,2}^{i,z}, \Psi_{m,2}^{i,l}, i\in \mathcal{I}_{case2} \}\cup \{\Psi_{m,3}^{j,z}, \Psi_{m,3}^{j,l}, j\in \mathcal{I}_{case3}\}$.
The boundary sequence partitions the space of the MPO's price per VM $\Psi_m^v$ into $2I + 1$ intervals.
\begin{equation}
0 \cup \mathbb{R}^{+} = \mathcal{M}^1 \cup \mathcal{M}^2 \cdots \cup \mathcal{M}^{2I+1}
\end{equation}
Within each interval $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$, we define four sets of ASP $i$ that has different optimal responses.
\begin{equation}
\begin{aligned}
&\Omega^{k,z} = \{i \in \mathcal{I}|(z_{i}^v(\Psi_m^v))^* = 0\} \\
&\Omega^{k,l} = \{i \in \mathcal{I}|(z_{i}^v(\Psi_m^v))^* = \frac{\lambda_i + \gamma_i}{\mu_i^v}\} \\
&\Omega^{k,e}_{2} = \{i \in \mathcal{I}_{case2}|(z_{i}^v(\Psi_m^v))^* = (z_{i,2}^{v,e}(\Psi_m^v))^*\}\\
&\Omega^{k,e}_{3} = \{i \in \mathcal{I}_{case3}|(z_{i}^v(\Psi_m^v))^* = (z_{i,3}^{v,e}(\Psi_m^v))^*\}
\end{aligned}
\end{equation}
These four sets form a partition of the all ASPs. That is, $\mathcal{I} = \Omega^{k,z} \cup \Omega^{k,l} \cup \Omega^{k,e}_{2} \cup \Omega^{k,e}_{3}, \, \forall k \in \{1, \cdots, 2I+1\}$. The total number of VMs bought by the ASPs within each interval $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$ can be expressed
\begin{equation}\label{eqn:total_number_VM}
\begin{aligned}
&\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^* =
\sum_{i\in \Omega^{k,l}}\frac{\lambda_i + \gamma_i}{\mu_i^v} \\
& + \sum_{i\in \Omega^{k,e}_{2}}(z_{i,2}^{v,e}(\Psi_m^v))^* + \sum_{i \in \Omega_3^{k,e}}(z_{i,3}^{v,e}(\Psi_m^v))^*
\end{aligned}
\end{equation}
Finally, the MPO's optimization problem in each interval $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$ is
\begin{maxi!}[2]
  {\Psi_m^v \in \mathcal{M}^k}
  {\Psi_m^v \cdot \sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^* - C_m^v\big(\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^*\big) \label{eqn:f_mpo_utility_opti_obj}}
  {\label{eqn:f_mpo_utility_opti}}
  {}
  \addConstraint{\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^* \leq \mathcal{Q}_v}{\label{eqn:f_mpo_utility_opti_const1}}
\end{maxi!}
%\begin{theorem} \label{thm:f_mpo_convex_optimization}
In each interval $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$, the MPO's optimization problem (\ref{eqn:f_mpo_utility_opti}) is a convex optimization problem. The optimal price per VM $\Psi_m^v$ is one of the optimal prices in each $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$ that gives the highest utility. 
%\end{theorem}
%The proof of convexity is omitted due to page limitation.


% Comment Out
\iffalse
\begin{proof}
We start by proving that $\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^*$ is convex in $\Psi_m^v$ when $\Psi_m^v \in \mathcal{M}^k,\, \forall k \in \mathcal{I}$. In (\ref{eqn:total_number_VM}), only the second and third term pertains to $\Psi_m^v$. As the summation of convex function is also a convex function, it suffices to prove that $(z_{i,2}^{v,e}(\Psi_m^v))^*$ is convex in $\Psi_m^v$ for $i \in \Omega_2^{k,e}$ and $(z_{i,3}^{v,e}(\Psi_m^v))^*$ is convex in $\Psi_m^v$ for $i \in \Omega_3^{k,e}$. Taking the second derivative of (\ref{eqn:asp_case2_utility_extreme}) with respect to $\Psi_m^v$, we have
\begin{equation}
\frac{3}{4}(\Psi_m^v)^{-5/2}\sqrt{\frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{(b_i-a_i)[(1-\xi_i)\mu_i^v + \xi_i \eta]}} \geq 0
\end{equation}
In addition, take the second derivative of (\ref{eqn:asp_case3_utility_extreme}) with respect to $\Psi_m^v$, we have
\begin{equation}
\frac{3}{4}(\Psi_m^v)^{-5/2}\sqrt{\frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{\mu_i^v(b_i-a_i)}} \geq 0
\end{equation}

Hence, $(z_{i,2}^v(\Psi_m^v))^*$ and $(z_{i,3}^v(\Psi_m^v))^*$ is convex in $\Psi_m^v \in \mathcal{M}^k,\, \forall k \in \{1,\cdots, 2I+1\}$. Since the sublevel set of a convex function is a convex set, the feasible region resulting from (\ref{eqn:f_mpo_utility_opti_const1}) is a convex set for any value $\mathcal{Q}_v$. In addition, the feasible region of (\ref{eqn:f_mpo_utility_opti_const2}) is also a convex set because the convex combination of two numbers in $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$ is still a number in $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$. Thus, the feasible region of the optimization problem (\ref{eqn:f_mpo_utility_opti}) is the intersection of two convex set and thus is a convex set. To prove that the MPO's the optimization problem (\ref{eqn:f_mpo_utility_opti}) is a convex optimization problem, what remains to do is to prove that the objective function (\ref{eqn:f_mpo_utility_opti_obj}) is concave in $\Psi_m^v \in \mathcal{M}^k,\, \forall k \in \{1,\cdots, 2I+1\}$. Using (\ref{eqn:asp_case2_utility_extreme}), (\ref{eqn:asp_case3_utility_extreme}) and (\ref{eqn:total_number_VM}), we can unfold the first term in (\ref{eqn:f_mpo_utility_opti_obj}) as follows.
\begin{align} \label{eqn:mpo_utility_first_term}
&\Psi_m^v \cdot \sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^* \\
&= \Psi_m^v\{\sum_{i\in \Omega^{k,l}}\frac{\lambda_i + \gamma_i}{\mu_i^v} + \sum_{i\in \Omega^{k,e}_{2}}(z_{i,2}^{v,e}(\Psi_m^v))^* +\sum_{i\in \Omega^{k,e}_{3}}(z_{i,3}^{v,e}(\Psi_m^v))^*\} \nonumber\\
\end{align}
The first term (\ref{eqn:mpo_utility_first_term}) is a linear function of $\Psi_m^v$ which is both convex and concave. The second and third term $(\ref{eqn:mpo_utility_first_term})$ is concave in $\Psi_m^v$. To see this, we check the concavity via the second order test. The second derivative of the second term is
\begin{equation}
-\frac{1}{4}(\Psi_m^v)^{-3/2}\sum_{i \in \Omega_2^{k,e}} \sqrt{\frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{(b_i-a_i)[(1-\xi_i)\mu_i^v + \xi_i \eta]}} \leq 0
\end{equation}
And the second derivative of the third term is
\begin{equation}
-\frac{1}{4}(\Psi_m^v)^{-3/2}\sum_{i \in \Omega_3^{k,e}} \sqrt{\frac{\sum_{j \in \mathrm{U}_i^n}\Psi_{ij}}{\mu_i^v(b_i-a_i)}} \leq 0
\end{equation}
Therefore, (\ref{eqn:mpo_utility_first_term}) is concave in $\Psi_m^v$. The second term of (\ref{eqn:f_mpo_utility_opti_obj}), $C_m^v\big(\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))^*$, is convex in $\Psi_m^v$ as it is a composition of $C_m^v$ and $\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v)$ where $C_m^v$ is convex and non-decreasing, and $\sum_{i \in \mathcal{I}} (z_{i}^v(\Psi_m^v))$ is convex in $\Psi_m^v \in \mathcal{M}^k,\, \forall k \in \{1, \cdots, 2I+1\}$. Since a concave function minus a convex function yields a concave function, (\ref{eqn:f_mpo_utility_opti_obj}) is concave in $\Psi_m^v \in \mathcal{M}^k,\, \forall k \in \mathcal{I}$. In sum, the MPO's optimization problem (\ref{eqn:f_mpo_utility_opti}) in each interval $\mathcal{M}^k, \forall k \in \{1, \cdots, 2I+1\}$ is a convex optimization problem. \qedhere
\end{proof}
\fi
 % Comment Out
 
By the above property, we can find the optimal price of VM for the MPO per interval. We then derive the optimal price $\Psi_m^v$ in all regions for the MPO.

% Comment out
\iffalse
\begin{theorem} \label{thm:stackelberg_game_equilibrium}
There are at lease one Stackelberg game equilibrium in our system after the modifications.
\end{theorem}
\begin{proof}
In Case 1, we have analytical solutions for ASPs' optimal number of VMs to buy from the MPO by \Cref{thm:asp_case1_optimal}. The best response sets for ASPs defined in (\ref{eqn:asp_best_response}) are non-empty. With the optimal responses from the ASPs, the MPO's optimal price per VM $\Psi_m^v$ exists becasue when (\ref{eqn:case1_mpo_utility_opti_const2}) becomes $\Psi_m^v \in \mathcal{M}_1^{k'}$, MPO's optimization problem is a convex optimization problem proved in \Cref{thm:mpo_case1_convex_optimization} with a compact feasible region. Thus, the MPO's best response set definded in (\ref{eqn:mpo_best_response}) is non-empty. By \Cref{def:stackelberg_equilibrium}, there are at least one Stackelberg game equlibrium in Case 1. Similarly, in Case 2, we have analytical solutions for ASPs' optimal number of VMs to buy from the MPO by \Cref{thm:asp_case2_optimal}. The best response sets for ASPs defined in (\ref{eqn:asp_best_response}) are non-empty. With the optimal responses from the ASPs, the MPO's optimal price per VM $\Psi_m^v$ exists becasue becasue when (\ref{eqn:case2_mpo_utility_opti_const2}) becomes $\Psi_m^v \in \mathcal{M}_2^{k'}$, MPO's optimization problem is a convex optimization problem proved in \Cref{thm:mpo_case2_convex_optimization} with a compact feasible region. Thus, the MPO's best response set definded in (\ref{eqn:mpo_best_response}) is non-empty. By \Cref{def:stackelberg_equilibrium}, there are at least one Stackelberg game equlibrium in Case 2. Finally, in Case 3, we have analytical solutions for ASPs' optimal number of VMs to buy from the MPO by \Cref{thm:asp_case4_optimal}. The best response sets for ASPs defined in (\ref{eqn:asp_best_response}) are non-empty. With the optimal responses from the ASPs, the MPO's optimal price per VM $\Psi_m^v$ exists becasue becasue when (\ref{eqn:case4_mpo_utility_opti_const2}) becomes $\Psi_m^v \in \mathcal{M}_3^{k'}$, MPO's optimization problem is a convex optimization problem proved in \Cref{thm:mpo_case4_convex_optimization} with a compact feasible region. Thus, the MPO's best response set definded in (\ref{eqn:mpo_best_response}) is non-empty. By \Cref{def:stackelberg_equilibrium}, there are at least one Stackelberg game equilibrium in Case 3.
\end{proof}
Because of \Cref{thm:mpo_case1_convex_optimization}, \Cref{thm:mpo_case2_convex_optimization}, and \Cref{thm:mpo_case4_convex_optimization}, if the specific form of $C_m^v(\cdot)$ is given, we can solve the exact form of the solution to the MPO's optimization problem. We will select some specific forms for $C_m^v(\cdot)$ in the \Cref{sec:simulation}.
\fi
% Comment out


\section{Simulation} \label{sec:simulation}

\begin{figure}
    \centering
  \includegraphics[width=0.45\textwidth]{5GDDoS_Game_vm_number.pdf}
  \caption{Total Purchased VM v.s. MPO Price}
\vspace{-0.8em}
  \label{subfig-1:VMnum}
\end{figure}
\begin{figure}
    \centering
  \includegraphics[width=0.45\textwidth]{5GDDoS_Game_utility.pdf}
\caption{MPO Utility v.s. MPO Price}
\vspace{-0.8em}
\label{subfig-2:MPOutil}
\end{figure}

%\subsection{Simulation Setup}
We evaluate the performance of the proposed Stackelberg equilibrium with simulations. We simulate a MEC system with one MPO and five ASPs. For the MPO, the CPU frequency per VM $f_m^v$ is 0.25GHz, and the cost function is set to be $C_m^v(x) = 100e^x$. For each ASP, the bandwidth $B_i$ is 20MHz, the transmission power $p_i$ is 23dBm\cite{3gpp.36.101}, the background noise power $N_0$ is -100dBm\cite{chen2015efficient}. For path loss model, we use $g(d)=22log_{10}(d)+28+20log_{10}(f_c)$ \cite{3gpp.36.814}, where $d$ is the distance between EUs and ASPs, and $f_c$ is the frequency band. As for other system parameters, $\xi_{i}$ is 0.999, $\gamma_i$ is 100, and the frequency band $f_c$ is 2.1GHz.

For EUs, the distance between EU and ASP is uniformly chosen from 50m to 100m, the task size $s_{ij}$ is uniformly chosen from 4kB to 5kB, the latency requirements of the EU are chosen uniformly between 5ms to 100ms, the required CPU cycles $\chi_{ij}$ are chosen uniform between 0.1 and 0.9 Megacycles, the arrival rate $\lambda_{ij}$ is chosen uniformly between 1 and 3\cite{fan2018application}, and the payments of the EUs $\Psi_{ij}$ are chosen uniformly between 1 and 10.


If not specified, the ratio of malicious users to normal users is set to 0.5, and the number of EUs is set to 100 per ASP. The IPS efficiency $\eta$ is set to be 5000. 

\iffalse
\begin{figure}[!ht]
     \subfloat[Total Purchased VM v.s. MPO Price\label{subfig-1:VMnum}]{%
       \includegraphics[width=0.24\textwidth]{5GDDoS_Game_vm_number.pdf}
     }
     \subfloat[MPO Utility v.s. MPO Price\label{subfig-2:MPOutil}]{%
       \includegraphics[width=0.24\textwidth]{5GDDoS_Game_utility.pdf}
     }
     \\
     \subfloat[Different Malicious Users to Normal Users Ratio\label{subfig-1:ratio}]{%
       \includegraphics[width=0.24\textwidth]{5GDDoS_Game_social_ratio.pdf}
     }
     \subfloat[Different Number of End users\label{subfig-2:num_cmp}]{%
       \includegraphics[width=0.24\textwidth]{5GDDoS_Game_social_device.pdf}
     }
     \caption{Simulation Result}
     \label{fig:sim}
  \end{figure}
\fi



We first verify the convexity of the MPO optimization problem. The boundaries of price interval have been plot and shown in \Cref{subfig-1:VMnum} and \Cref{subfig-2:MPOutil}. The ASP has the same optimal response in every interval. As the MPO price increases, the optimal responses by the ASPs changes from a decreasing, convex function ((\Cref{eqn:asp_case2_utility_extreme}) and (\Cref{eqn:asp_case3_utility_extreme})) to a constant. Moreover, the MPO utility shown in \Cref{subfig-2:MPOutil} is a concave function in every interval. %Thus, we can solve the MPO optimization problem by solving the convex optimization problem in every interval. 


Then, we compare the different IPS allocation schemes in scenarios of different malicious to normal users ratio. Three rules are compared: No IPS, $30\%$ IPS VM., and Proposed scheme.  As seen in \Cref{subfig-1:ratio}, when the ratio increases, the overall social welfare decreases regardless of the applied scheme due to the increased attacks. Nevertheless, the Proposed deployment reaches the highest social welfare compared with other baselines regardless of the ratio. 

We further compare different IPS allocation schemes in scenarios of various numbers of end-users. As seen in \Cref{subfig-2:num_cmp}, when the number of devices increases, the social welfare increases initially, but then decreases after the device number exceeds 150. As the device number started to exceed the available resource the MEC server can handle, ASP cannot serve excess EUs in time, thus the social welfare drops. Nevertheless, the proposed scheme still has the highest social welfare compare with other baselines.

\begin{figure}
    \centering
  \includegraphics[width=0.45\textwidth]{5GDDoS_Game_social_ratio.pdf}
    \caption{Different Malicious Users to Normal Users Ratio}
\vspace{-0.8em}
\label{subfig-1:ratio}
\end{figure}

\begin{figure}
    \centering
  \includegraphics[width=0.45\textwidth]{5GDDoS_Game_social_device.pdf}
\caption{Different Number of End users}
\vspace{-0.8em}
\label{subfig-2:num_cmp}
\end{figure}

\section{Conclusion} \label{sec:conclusion}
In the paper, we proposed a flexible IPS deployment strategy for ASPs to determine the allocation of VM resources for IPS and services to mitigate the expected DDoS attacks. The joint optimization problem of ASP and MPO is formulated as a Stackelberg game to capture the hierarchy relationship. The optimal pricing strategy of MPO and the optimal amount of purchased MV along with the ratio of IPS VM for ASPs are derived. The simulation results verify the effectiveness of the proposed solution in maintaining the service quality and social welfare compared with other baseline schemes.


\bibliographystyle{IEEEtran}
\bibliography{5GDDoS_Game}

\end{document}
